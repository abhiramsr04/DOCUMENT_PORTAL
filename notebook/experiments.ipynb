{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "703656d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pront allez!\n"
     ]
    }
   ],
   "source": [
    "print(\"Pront allez!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6b8b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb0fbf25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f0058db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq( model=\"qwen/qwen3-32b\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b924ce1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, so I need to figure out the capital of France. Hmm, let's see. I remember from school that France is a country in Europe, right? And capitals are usually big cities. I think Paris is the capital. Wait, isn't Paris known for the Eiffel Tower and the Louvre? Yeah, that sounds familiar. But wait, maybe it's another city like Lyon or Marseille? No, Lyon is a major city, but I think Paris is more prominent. Let me try to recall if there's any other city that could be the capital. Maybe Strasbourg? No, Strasbourg is in the Alsace region, and I think the European Parliament is there, but that's not the capital of France. What about Bordeaux? No, that's more of a wine region. Oh, right, the capital of France is definitely Paris. But just to be sure, isn't Paris the political and administrative center? Yeah, that's right. I think the government is based there. So, yeah, the answer should be Paris.\\n</think>\\n\\nThe capital of France is **Paris**. It serves as the political, economic, and cultural center of the country. Notable landmarks such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral are located in Paris, further cementing its status as a world-renowned city. \\n\\n**Answer:** Paris.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"What is the capital of France?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26cd73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e25abad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embeddings-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9582d717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Agentic AI\\projects\\DOCUMENT_PORTAL\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 768\n",
      "First 5 values: [0.037376475, -0.0800528, 0.009497141, -0.0542599, 0.04019698]\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Embed a query\n",
    "result = genai.embed_content(\n",
    "    model=\"embedding-001\",\n",
    "    content=\"What is the capital of France?\",\n",
    "    task_type=\"retrieval_query\",\n",
    ")\n",
    "\n",
    "embedding = result[\"embedding\"]\n",
    "print(f\"Length: {len(embedding)}\")\n",
    "print(\"First 5 values:\", embedding[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d297aa9",
   "metadata": {},
   "source": [
    "1.DATA INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa12897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd0b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457e406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"data\", \"sample.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3756a39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Agentic AI\\\\projects\\\\DOCUMENT_PORTAL\\\\notebook'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95510625",
   "metadata": {},
   "outputs": [],
   "source": [
    "Documents = PyPDFLoader(file_path=file_path).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d61bda28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, calledLlama 2-Chat, are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nour human evaluations for helpfulness and safety, may be a suitable substitute for closed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements ofLlama 2-Chatin order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.\\narXiv:2307.09288v2  [cs.CL]  19 Jul 2023'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be7e456e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b21818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36900b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eaca10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dfe0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
